server.host=127.0.0.1

cluster-node.system-name=cluster
cluster-node.topics=node1,test
cluster-node.port=3551
cluster-node.seeds=127.0.0.1:3551
cluster-node.metrics.sample-interval=5s
cluster-node.metrics.topic=cluster-node-metrics
cluster-node.metrics.name=cluster-node-metrics
cluster-node.task-info.trigger.interval=3 second
cluster-node.logger=${logger}
cluster-node.persistence.dir=data

client-node.system-name=client
client-node.port=4551
client-node.logger=${logger}

file-server.context-path=file
file-server.port=8011
file-server.chunk-size=8192
file-server.base-path=
file-server.system-name=file-server
file-server.recursive-transfer-max=100
file-server.dispatcher.core-pool-size-min=12
file-server.dispatcher.core-pool-size-factor=6
file-server.dispatcher.core-pool-size-max=72
file-server.host-connection.pool.max-connections=24
file-server.host-connection.pool.min-connections=1
file-server.host-connection.pool.max-retries=5
file-server.host-connection.pool.max-open-requests=128
file-server.logger=${logger}

exec.shell.cmd=/bin/bash
exec.java.enabled=true
exec.java.cmd=java
exec.python.enabled=true
exec.python.cmd=python
exec.scala.enabled=true
exec.scala.cmd=scala
exec.work-dir=exec
exec.thread-num=20
exec.max-timeout=24 hour

log.file.dir=log
log.file.name=task-executor.%d{yyyy-MM-dd}.log
log.file.pattern=[%-5level] %date{ISO8601} [%-46logger] - %msg%n
log.file.max-history=30
log.file.max-size=10MB
log.stdout.pattern=[%highlight(%-5level)] %date{ISO8601} [%-46logger] - %msg%n
dev-mode=true
logger=akka.event.slf4j.Slf4jLogger

hadoop.home=C:/Users/chenmingkun/Documents/hadoop
hadoop.conf.dir=${hadoop.home}/etc/hadoop

